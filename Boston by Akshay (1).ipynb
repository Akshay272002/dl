{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61901a29-8ac9-49c6-b1be-7a9a053d779b",
   "metadata": {},
   "outputs": [],
   "source": [
    "*import pandas as pd\n",
    "import matplotlib.pyplot as plt*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c6ff666-0ccd-4f17-a1dd-ea61594495c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "      <th>CAT. MEDV</th>\n",
       "      <th>Unnamed: 15</th>\n",
       "      <th>Unnamed: 16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.02985</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.430</td>\n",
       "      <td>58.7</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.12</td>\n",
       "      <td>5.21</td>\n",
       "      <td>28.7</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.08829</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.012</td>\n",
       "      <td>66.6</td>\n",
       "      <td>5.5605</td>\n",
       "      <td>5</td>\n",
       "      <td>311</td>\n",
       "      <td>15.2</td>\n",
       "      <td>395.60</td>\n",
       "      <td>12.43</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.14455</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.172</td>\n",
       "      <td>96.1</td>\n",
       "      <td>5.9505</td>\n",
       "      <td>5</td>\n",
       "      <td>311</td>\n",
       "      <td>15.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>19.15</td>\n",
       "      <td>27.1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.21124</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>5.631</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6.0821</td>\n",
       "      <td>5</td>\n",
       "      <td>311</td>\n",
       "      <td>15.2</td>\n",
       "      <td>386.63</td>\n",
       "      <td>29.93</td>\n",
       "      <td>16.5</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.17004</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.004</td>\n",
       "      <td>85.9</td>\n",
       "      <td>6.5921</td>\n",
       "      <td>5</td>\n",
       "      <td>311</td>\n",
       "      <td>15.2</td>\n",
       "      <td>386.71</td>\n",
       "      <td>17.10</td>\n",
       "      <td>18.9</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM    AGE     DIS  RAD  TAX  PTRATIO  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575   65.2  4.0900    1  296     15.3   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421   78.9  4.9671    2  242     17.8   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185   61.1  4.9671    2  242     17.8   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998   45.8  6.0622    3  222     18.7   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147   54.2  6.0622    3  222     18.7   \n",
       "5  0.02985   0.0   2.18     0  0.458  6.430   58.7  6.0622    3  222     18.7   \n",
       "6  0.08829  12.5   7.87     0  0.524  6.012   66.6  5.5605    5  311     15.2   \n",
       "7  0.14455  12.5   7.87     0  0.524  6.172   96.1  5.9505    5  311     15.2   \n",
       "8  0.21124  12.5   7.87     0  0.524  5.631  100.0  6.0821    5  311     15.2   \n",
       "9  0.17004  12.5   7.87     0  0.524  6.004   85.9  6.5921    5  311     15.2   \n",
       "\n",
       "        B  LSTAT  MEDV  CAT. MEDV  Unnamed: 15  Unnamed: 16  \n",
       "0  396.90   4.98  24.0          0          NaN          NaN  \n",
       "1  396.90   9.14  21.6          0          NaN          NaN  \n",
       "2  392.83   4.03  34.7          1          NaN          NaN  \n",
       "3  394.63   2.94  33.4          1          NaN          NaN  \n",
       "4  396.90   5.33  36.2          1          NaN          NaN  \n",
       "5  394.12   5.21  28.7          0          NaN          NaN  \n",
       "6  395.60  12.43  22.9          0          NaN          NaN  \n",
       "7  396.90  19.15  27.1          0          NaN          NaN  \n",
       "8  386.63  29.93  16.5          0          NaN          NaN  \n",
       "9  386.71  17.10  18.9          0          NaN          NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "*df = pd.read_csv('C:/Users/hp/Downloads/Boston.csv')\n",
    "df.head(10)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "910baef3-36d0-41da-a9b2-80b7e522a7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "*df.drop(columns=['Unnamed: 15','Unnamed: 16'],inplace=True)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4ba3a53-c702-4c3c-95e9-9686ee1b74b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "*df.drop(columns=['CAT. MEDV'],inplace=True)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72b4644c-451c-49b4-8b11-b662aa6f23fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM       0\n",
       "ZN         0\n",
       "INDUS      0\n",
       "CHAS       0\n",
       "NOX        0\n",
       "RM         0\n",
       "AGE        0\n",
       "DIS        0\n",
       "RAD        0\n",
       "TAX        0\n",
       "PTRATIO    0\n",
       "B          0\n",
       "LSTAT      0\n",
       "MEDV       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "*df.isnull().sum()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf7602f9-d2be-4f5a-8401-d209dbb533d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 14 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   CRIM     506 non-null    float64\n",
      " 1   ZN       506 non-null    float64\n",
      " 2   INDUS    506 non-null    float64\n",
      " 3   CHAS     506 non-null    int64  \n",
      " 4   NOX      506 non-null    float64\n",
      " 5   RM       506 non-null    float64\n",
      " 6   AGE      506 non-null    float64\n",
      " 7   DIS      506 non-null    float64\n",
      " 8   RAD      506 non-null    int64  \n",
      " 9   TAX      506 non-null    int64  \n",
      " 10  PTRATIO  506 non-null    float64\n",
      " 11  B        506 non-null    float64\n",
      " 12  LSTAT    506 non-null    float64\n",
      " 13  MEDV     506 non-null    float64\n",
      "dtypes: float64(11), int64(3)\n",
      "memory usage: 55.5 KB\n"
     ]
    }
   ],
   "source": [
    "*df.info()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b659098f-5631-4dff-8a99-26c7e3556628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.613524</td>\n",
       "      <td>11.363636</td>\n",
       "      <td>11.136779</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.554695</td>\n",
       "      <td>6.284634</td>\n",
       "      <td>68.574901</td>\n",
       "      <td>3.795043</td>\n",
       "      <td>9.549407</td>\n",
       "      <td>408.237154</td>\n",
       "      <td>18.455534</td>\n",
       "      <td>356.674032</td>\n",
       "      <td>12.653063</td>\n",
       "      <td>22.532806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.601545</td>\n",
       "      <td>23.322453</td>\n",
       "      <td>6.860353</td>\n",
       "      <td>0.253994</td>\n",
       "      <td>0.115878</td>\n",
       "      <td>0.702617</td>\n",
       "      <td>28.148861</td>\n",
       "      <td>2.105710</td>\n",
       "      <td>8.707259</td>\n",
       "      <td>168.537116</td>\n",
       "      <td>2.164946</td>\n",
       "      <td>91.294864</td>\n",
       "      <td>7.141062</td>\n",
       "      <td>9.197104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>3.561000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.129600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>1.730000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.082045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>5.885500</td>\n",
       "      <td>45.025000</td>\n",
       "      <td>2.100175</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>375.377500</td>\n",
       "      <td>6.950000</td>\n",
       "      <td>17.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.256510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.208500</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>3.207450</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>19.050000</td>\n",
       "      <td>391.440000</td>\n",
       "      <td>11.360000</td>\n",
       "      <td>21.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.677083</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>6.623500</td>\n",
       "      <td>94.075000</td>\n",
       "      <td>5.188425</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>396.225000</td>\n",
       "      <td>16.955000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>88.976200</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.780000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12.126500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>396.900000</td>\n",
       "      <td>37.970000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             CRIM          ZN       INDUS        CHAS         NOX          RM  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean     3.613524   11.363636   11.136779    0.069170    0.554695    6.284634   \n",
       "std      8.601545   23.322453    6.860353    0.253994    0.115878    0.702617   \n",
       "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
       "25%      0.082045    0.000000    5.190000    0.000000    0.449000    5.885500   \n",
       "50%      0.256510    0.000000    9.690000    0.000000    0.538000    6.208500   \n",
       "75%      3.677083   12.500000   18.100000    0.000000    0.624000    6.623500   \n",
       "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
       "\n",
       "              AGE         DIS         RAD         TAX     PTRATIO           B  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean    68.574901    3.795043    9.549407  408.237154   18.455534  356.674032   \n",
       "std     28.148861    2.105710    8.707259  168.537116    2.164946   91.294864   \n",
       "min      2.900000    1.129600    1.000000  187.000000   12.600000    0.320000   \n",
       "25%     45.025000    2.100175    4.000000  279.000000   17.400000  375.377500   \n",
       "50%     77.500000    3.207450    5.000000  330.000000   19.050000  391.440000   \n",
       "75%     94.075000    5.188425   24.000000  666.000000   20.200000  396.225000   \n",
       "max    100.000000   12.126500   24.000000  711.000000   22.000000  396.900000   \n",
       "\n",
       "            LSTAT        MEDV  \n",
       "count  506.000000  506.000000  \n",
       "mean    12.653063   22.532806  \n",
       "std      7.141062    9.197104  \n",
       "min      1.730000    5.000000  \n",
       "25%      6.950000   17.025000  \n",
       "50%     11.360000   21.200000  \n",
       "75%     16.955000   25.000000  \n",
       "max     37.970000   50.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "*df.describe()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8cdddad5-9925-481f-ab55-0cfed34adf2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTAT     -0.737663\n",
       "PTRATIO   -0.507787\n",
       "INDUS     -0.483725\n",
       "TAX       -0.468536\n",
       "NOX       -0.427321\n",
       "CRIM      -0.388305\n",
       "RAD       -0.381626\n",
       "AGE       -0.376955\n",
       "CHAS       0.175260\n",
       "DIS        0.249929\n",
       "B          0.333461\n",
       "ZN         0.360445\n",
       "RM         0.695360\n",
       "MEDV       1.000000\n",
       "Name: MEDV, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "*df.corr()['MEDV'].sort_values()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7bb27d01-c199-4279-a8e2-3128b4409900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((506, 3), (506,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "*X = df.loc[:,['LSTAT','PTRATIO','RM']]\n",
    "Y = df.loc[:,\"MEDV\"]\n",
    "X.shape,Y.shape*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f2d010b-7f69-4158-97ae-1d5ec6660ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "*from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size=0.25,random_state=10)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1165c94a-4516-405c-a5a2-cddf64ea4f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "*from sklearn.preprocessing import StandardScaler*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0db4ea04-5ed2-48c8-aa9f-9f0259821259",
   "metadata": {},
   "outputs": [],
   "source": [
    "*scaler = StandardScaler()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef148ae4-50f0-4547-b0eb-f29852f967d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StandardScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;StandardScaler<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "*scaler.fit(x_train)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c0c8c533-8e8e-42ce-a54c-c6015f6af91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "*x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6d823c45-88d3-4ec2-ad64-3b1b650b0eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Downloading keras-3.9.2-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting absl-py (from keras)\n",
      "  Downloading absl_py-2.2.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\hp\\anaconda3\\lib\\site-packages (from keras) (1.26.4)\n",
      "Requirement already satisfied: rich in c:\\users\\hp\\anaconda3\\lib\\site-packages (from keras) (13.7.1)\n",
      "Collecting namex (from keras)\n",
      "  Downloading namex-0.0.9-py3-none-any.whl.metadata (322 bytes)\n",
      "Requirement already satisfied: h5py in c:\\users\\hp\\anaconda3\\lib\\site-packages (from keras) (3.11.0)\n",
      "Collecting optree (from keras)\n",
      "  Downloading optree-0.15.0-cp312-cp312-win_amd64.whl.metadata (49 kB)\n",
      "Collecting ml-dtypes (from keras)\n",
      "  Downloading ml_dtypes-0.5.1-cp312-cp312-win_amd64.whl.metadata (22 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\hp\\anaconda3\\lib\\site-packages (from keras) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from optree->keras) (4.11.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from rich->keras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from rich->keras) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.0)\n",
      "Downloading keras-3.9.2-py3-none-any.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.3/1.3 MB 7.7 MB/s eta 0:00:00\n",
      "Downloading absl_py-2.2.2-py3-none-any.whl (135 kB)\n",
      "Downloading ml_dtypes-0.5.1-cp312-cp312-win_amd64.whl (210 kB)\n",
      "Downloading namex-0.0.9-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.15.0-cp312-cp312-win_amd64.whl (307 kB)\n",
      "Installing collected packages: namex, optree, ml-dtypes, absl-py, keras\n",
      "Successfully installed absl-py-2.2.2 keras-3.9.2 ml-dtypes-0.5.1 namex-0.0.9 optree-0.15.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "*pip install keras*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cacb8f01-c522-4feb-9510-c7b7d8631320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.19.0-cp312-cp312-win_amd64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (2.2.2)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (1.14.1)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.71.0-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard~=2.19.0 (from tensorflow)\n",
      "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (3.9.2)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\users\\hp\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\hp\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n",
      "Requirement already satisfied: optree in c:\\users\\hp\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.4.1)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.0)\n",
      "Downloading tensorflow-2.19.0-cp312-cp312-win_amd64.whl (376.0 MB)\n",
      "   ---------------------------------------- 0.0/376.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.6/376.0 MB 9.3 MB/s eta 0:00:41\n",
      "   ---------------------------------------- 3.7/376.0 MB 9.9 MB/s eta 0:00:38\n",
      "    --------------------------------------- 5.8/376.0 MB 9.8 MB/s eta 0:00:38\n",
      "    --------------------------------------- 7.6/376.0 MB 9.4 MB/s eta 0:00:40\n",
      "   - -------------------------------------- 10.0/376.0 MB 9.8 MB/s eta 0:00:38\n",
      "   - -------------------------------------- 12.3/376.0 MB 10.2 MB/s eta 0:00:36\n",
      "   - -------------------------------------- 14.7/376.0 MB 10.4 MB/s eta 0:00:35\n",
      "   - -------------------------------------- 17.0/376.0 MB 10.4 MB/s eta 0:00:35\n",
      "   -- ------------------------------------- 19.4/376.0 MB 10.6 MB/s eta 0:00:34\n",
      "   -- ------------------------------------- 21.8/376.0 MB 10.6 MB/s eta 0:00:34\n",
      "   -- ------------------------------------- 24.4/376.0 MB 10.9 MB/s eta 0:00:33\n",
      "   -- ------------------------------------- 26.7/376.0 MB 10.9 MB/s eta 0:00:33\n",
      "   --- ------------------------------------ 29.1/376.0 MB 10.9 MB/s eta 0:00:32\n",
      "   --- ------------------------------------ 31.5/376.0 MB 11.0 MB/s eta 0:00:32\n",
      "   --- ------------------------------------ 34.1/376.0 MB 11.0 MB/s eta 0:00:31\n",
      "   --- ------------------------------------ 36.4/376.0 MB 11.1 MB/s eta 0:00:31\n",
      "   ---- ----------------------------------- 38.8/376.0 MB 11.1 MB/s eta 0:00:31\n",
      "   ---- ----------------------------------- 41.2/376.0 MB 11.1 MB/s eta 0:00:31\n",
      "   ---- ----------------------------------- 43.5/376.0 MB 11.2 MB/s eta 0:00:30\n",
      "   ---- ----------------------------------- 45.6/376.0 MB 11.1 MB/s eta 0:00:30\n",
      "   ----- ---------------------------------- 48.2/376.0 MB 11.1 MB/s eta 0:00:30\n",
      "   ----- ---------------------------------- 50.6/376.0 MB 11.1 MB/s eta 0:00:30\n",
      "   ----- ---------------------------------- 53.0/376.0 MB 11.2 MB/s eta 0:00:29\n",
      "   ----- ---------------------------------- 55.3/376.0 MB 11.2 MB/s eta 0:00:29\n",
      "   ------ --------------------------------- 57.9/376.0 MB 11.2 MB/s eta 0:00:29\n",
      "   ------ --------------------------------- 60.0/376.0 MB 11.2 MB/s eta 0:00:29\n",
      "   ------ --------------------------------- 62.4/376.0 MB 11.3 MB/s eta 0:00:28\n",
      "   ------ --------------------------------- 64.7/376.0 MB 11.2 MB/s eta 0:00:28\n",
      "   ------- -------------------------------- 67.1/376.0 MB 11.3 MB/s eta 0:00:28\n",
      "   ------- -------------------------------- 69.2/376.0 MB 11.2 MB/s eta 0:00:28\n",
      "   ------- -------------------------------- 70.5/376.0 MB 11.1 MB/s eta 0:00:28\n",
      "   ------- -------------------------------- 72.4/376.0 MB 11.0 MB/s eta 0:00:28\n",
      "   ------- -------------------------------- 74.7/376.0 MB 11.0 MB/s eta 0:00:28\n",
      "   -------- ------------------------------- 77.1/376.0 MB 11.0 MB/s eta 0:00:28\n",
      "   -------- ------------------------------- 79.7/376.0 MB 11.1 MB/s eta 0:00:27\n",
      "   -------- ------------------------------- 82.1/376.0 MB 11.1 MB/s eta 0:00:27\n",
      "   --------- ------------------------------ 84.7/376.0 MB 11.1 MB/s eta 0:00:27\n",
      "   --------- ------------------------------ 87.0/376.0 MB 11.1 MB/s eta 0:00:27\n",
      "   --------- ------------------------------ 88.9/376.0 MB 11.1 MB/s eta 0:00:26\n",
      "   --------- ------------------------------ 91.5/376.0 MB 11.1 MB/s eta 0:00:26\n",
      "   --------- ------------------------------ 93.8/376.0 MB 11.1 MB/s eta 0:00:26\n",
      "   ---------- ----------------------------- 95.9/376.0 MB 11.1 MB/s eta 0:00:26\n",
      "   ---------- ----------------------------- 98.0/376.0 MB 11.1 MB/s eta 0:00:26\n",
      "   ---------- ---------------------------- 100.9/376.0 MB 11.1 MB/s eta 0:00:25\n",
      "   ---------- ---------------------------- 103.3/376.0 MB 11.1 MB/s eta 0:00:25\n",
      "   ---------- ---------------------------- 105.9/376.0 MB 11.2 MB/s eta 0:00:25\n",
      "   ----------- --------------------------- 108.3/376.0 MB 11.2 MB/s eta 0:00:24\n",
      "   ----------- --------------------------- 111.4/376.0 MB 11.2 MB/s eta 0:00:24\n",
      "   ----------- --------------------------- 112.7/376.0 MB 11.3 MB/s eta 0:00:24\n",
      "   ----------- --------------------------- 114.0/376.0 MB 11.1 MB/s eta 0:00:24\n",
      "   ------------ -------------------------- 116.7/376.0 MB 11.1 MB/s eta 0:00:24\n",
      "   ------------ -------------------------- 119.0/376.0 MB 11.1 MB/s eta 0:00:24\n",
      "   ------------ -------------------------- 121.9/376.0 MB 11.2 MB/s eta 0:00:23\n",
      "   ------------ -------------------------- 124.8/376.0 MB 11.2 MB/s eta 0:00:23\n",
      "   ------------- ------------------------- 127.1/376.0 MB 11.2 MB/s eta 0:00:23\n",
      "   ------------- ------------------------- 130.0/376.0 MB 11.3 MB/s eta 0:00:22\n",
      "   ------------- ------------------------- 132.6/376.0 MB 11.3 MB/s eta 0:00:22\n",
      "   ------------- ------------------------- 134.7/376.0 MB 11.3 MB/s eta 0:00:22\n",
      "   -------------- ------------------------ 137.4/376.0 MB 11.3 MB/s eta 0:00:22\n",
      "   -------------- ------------------------ 140.0/376.0 MB 11.3 MB/s eta 0:00:21\n",
      "   -------------- ------------------------ 142.9/376.0 MB 11.3 MB/s eta 0:00:21\n",
      "   --------------- ----------------------- 145.5/376.0 MB 11.3 MB/s eta 0:00:21\n",
      "   --------------- ----------------------- 148.1/376.0 MB 11.4 MB/s eta 0:00:21\n",
      "   --------------- ----------------------- 151.0/376.0 MB 11.4 MB/s eta 0:00:20\n",
      "   --------------- ----------------------- 153.4/376.0 MB 11.4 MB/s eta 0:00:20\n",
      "   ---------------- ---------------------- 156.0/376.0 MB 11.4 MB/s eta 0:00:20\n",
      "   ---------------- ---------------------- 158.9/376.0 MB 11.5 MB/s eta 0:00:19\n",
      "   ---------------- ---------------------- 161.5/376.0 MB 11.5 MB/s eta 0:00:19\n",
      "   ---------------- ---------------------- 163.8/376.0 MB 11.5 MB/s eta 0:00:19\n",
      "   ----------------- --------------------- 166.7/376.0 MB 11.5 MB/s eta 0:00:19\n",
      "   ----------------- --------------------- 169.1/376.0 MB 11.5 MB/s eta 0:00:18\n",
      "   ----------------- --------------------- 171.7/376.0 MB 11.5 MB/s eta 0:00:18\n",
      "   ------------------ -------------------- 174.6/376.0 MB 11.6 MB/s eta 0:00:18\n",
      "   ------------------ -------------------- 176.9/376.0 MB 11.6 MB/s eta 0:00:18\n",
      "   ------------------ -------------------- 179.6/376.0 MB 11.6 MB/s eta 0:00:17\n",
      "   ------------------ -------------------- 181.7/376.0 MB 11.6 MB/s eta 0:00:17\n",
      "   ------------------- ------------------- 184.0/376.0 MB 11.5 MB/s eta 0:00:17\n",
      "   ------------------- ------------------- 186.4/376.0 MB 11.6 MB/s eta 0:00:17\n",
      "   ------------------- ------------------- 189.0/376.0 MB 11.6 MB/s eta 0:00:17\n",
      "   ------------------- ------------------- 191.9/376.0 MB 11.6 MB/s eta 0:00:16\n",
      "   -------------------- ------------------ 194.8/376.0 MB 11.6 MB/s eta 0:00:16\n",
      "   -------------------- ------------------ 197.7/376.0 MB 11.6 MB/s eta 0:00:16\n",
      "   -------------------- ------------------ 200.8/376.0 MB 11.7 MB/s eta 0:00:16\n",
      "   --------------------- ----------------- 203.2/376.0 MB 11.7 MB/s eta 0:00:15\n",
      "   --------------------- ----------------- 205.5/376.0 MB 11.7 MB/s eta 0:00:15\n",
      "   --------------------- ----------------- 208.1/376.0 MB 11.7 MB/s eta 0:00:15\n",
      "   --------------------- ----------------- 209.5/376.0 MB 11.6 MB/s eta 0:00:15\n",
      "   --------------------- ----------------- 212.1/376.0 MB 11.6 MB/s eta 0:00:15\n",
      "   ---------------------- ---------------- 214.2/376.0 MB 11.6 MB/s eta 0:00:14\n",
      "   ---------------------- ---------------- 216.8/376.0 MB 11.6 MB/s eta 0:00:14\n",
      "   ---------------------- ---------------- 218.9/376.0 MB 11.6 MB/s eta 0:00:14\n",
      "   ---------------------- ---------------- 221.5/376.0 MB 11.6 MB/s eta 0:00:14\n",
      "   ----------------------- --------------- 224.1/376.0 MB 11.6 MB/s eta 0:00:14\n",
      "   ----------------------- --------------- 226.8/376.0 MB 11.6 MB/s eta 0:00:13\n",
      "   ----------------------- --------------- 228.9/376.0 MB 11.6 MB/s eta 0:00:13\n",
      "   ------------------------ -------------- 232.0/376.0 MB 11.7 MB/s eta 0:00:13\n",
      "   ------------------------ -------------- 234.6/376.0 MB 11.7 MB/s eta 0:00:13\n",
      "   ------------------------ -------------- 237.5/376.0 MB 11.7 MB/s eta 0:00:12\n",
      "   ------------------------ -------------- 239.6/376.0 MB 11.7 MB/s eta 0:00:12\n",
      "   ------------------------- ------------- 243.3/376.0 MB 11.7 MB/s eta 0:00:12\n",
      "   ------------------------- ------------- 245.9/376.0 MB 11.7 MB/s eta 0:00:12\n",
      "   ------------------------- ------------- 248.5/376.0 MB 11.8 MB/s eta 0:00:11\n",
      "   ------------------------- ------------- 250.6/376.0 MB 11.7 MB/s eta 0:00:11\n",
      "   -------------------------- ------------ 252.7/376.0 MB 11.7 MB/s eta 0:00:11\n",
      "   -------------------------- ------------ 255.1/376.0 MB 11.7 MB/s eta 0:00:11\n",
      "   -------------------------- ------------ 257.4/376.0 MB 11.7 MB/s eta 0:00:11\n",
      "   --------------------------- ----------- 260.3/376.0 MB 11.7 MB/s eta 0:00:10\n",
      "   --------------------------- ----------- 262.4/376.0 MB 11.7 MB/s eta 0:00:10\n",
      "   --------------------------- ----------- 264.8/376.0 MB 11.7 MB/s eta 0:00:10\n",
      "   --------------------------- ----------- 267.1/376.0 MB 11.7 MB/s eta 0:00:10\n",
      "   --------------------------- ----------- 269.5/376.0 MB 11.8 MB/s eta 0:00:10\n",
      "   ---------------------------- ---------- 271.6/376.0 MB 11.7 MB/s eta 0:00:09\n",
      "   ---------------------------- ---------- 273.7/376.0 MB 11.7 MB/s eta 0:00:09\n",
      "   ---------------------------- ---------- 274.2/376.0 MB 11.7 MB/s eta 0:00:09\n",
      "   ---------------------------- ---------- 276.3/376.0 MB 11.6 MB/s eta 0:00:09\n",
      "   ---------------------------- ---------- 278.9/376.0 MB 11.7 MB/s eta 0:00:09\n",
      "   ----------------------------- --------- 281.5/376.0 MB 11.7 MB/s eta 0:00:09\n",
      "   ----------------------------- --------- 284.2/376.0 MB 11.7 MB/s eta 0:00:08\n",
      "   ----------------------------- --------- 286.5/376.0 MB 11.7 MB/s eta 0:00:08\n",
      "   ------------------------------ -------- 289.4/376.0 MB 11.7 MB/s eta 0:00:08\n",
      "   ------------------------------ -------- 291.8/376.0 MB 11.7 MB/s eta 0:00:08\n",
      "   ------------------------------ -------- 294.6/376.0 MB 11.7 MB/s eta 0:00:07\n",
      "   ------------------------------ -------- 297.3/376.0 MB 11.7 MB/s eta 0:00:07\n",
      "   ------------------------------- ------- 299.9/376.0 MB 11.7 MB/s eta 0:00:07\n",
      "   ------------------------------- ------- 302.5/376.0 MB 11.7 MB/s eta 0:00:07\n",
      "   ------------------------------- ------- 305.1/376.0 MB 11.8 MB/s eta 0:00:07\n",
      "   ------------------------------- ------- 307.8/376.0 MB 11.8 MB/s eta 0:00:06\n",
      "   -------------------------------- ------ 310.4/376.0 MB 11.8 MB/s eta 0:00:06\n",
      "   -------------------------------- ------ 312.7/376.0 MB 11.8 MB/s eta 0:00:06\n",
      "   -------------------------------- ------ 314.8/376.0 MB 11.8 MB/s eta 0:00:06\n",
      "   -------------------------------- ------ 315.1/376.0 MB 11.7 MB/s eta 0:00:06\n",
      "   -------------------------------- ------ 317.5/376.0 MB 11.7 MB/s eta 0:00:06\n",
      "   --------------------------------- ----- 319.6/376.0 MB 11.7 MB/s eta 0:00:05\n",
      "   --------------------------------- ----- 321.4/376.0 MB 11.6 MB/s eta 0:00:05\n",
      "   --------------------------------- ----- 323.5/376.0 MB 11.6 MB/s eta 0:00:05\n",
      "   --------------------------------- ----- 325.8/376.0 MB 11.6 MB/s eta 0:00:05\n",
      "   ---------------------------------- ---- 328.5/376.0 MB 11.6 MB/s eta 0:00:05\n",
      "   ---------------------------------- ---- 330.8/376.0 MB 11.6 MB/s eta 0:00:04\n",
      "   ---------------------------------- ---- 332.7/376.0 MB 11.7 MB/s eta 0:00:04\n",
      "   ---------------------------------- ---- 335.0/376.0 MB 11.7 MB/s eta 0:00:04\n",
      "   ---------------------------------- ---- 337.4/376.0 MB 11.7 MB/s eta 0:00:04\n",
      "   ----------------------------------- --- 339.0/376.0 MB 11.6 MB/s eta 0:00:04\n",
      "   ----------------------------------- --- 341.3/376.0 MB 11.6 MB/s eta 0:00:03\n",
      "   ----------------------------------- --- 343.1/376.0 MB 11.6 MB/s eta 0:00:03\n",
      "   ----------------------------------- --- 345.8/376.0 MB 11.6 MB/s eta 0:00:03\n",
      "   ------------------------------------ -- 347.9/376.0 MB 11.6 MB/s eta 0:00:03\n",
      "   ------------------------------------ -- 350.5/376.0 MB 11.6 MB/s eta 0:00:03\n",
      "   ------------------------------------ -- 353.1/376.0 MB 11.6 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 355.5/376.0 MB 11.6 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 357.6/376.0 MB 11.6 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 359.1/376.0 MB 11.6 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 361.2/376.0 MB 11.6 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 363.6/376.0 MB 11.6 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 366.0/376.0 MB 11.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  368.3/376.0 MB 11.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  370.9/376.0 MB 11.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  373.3/376.0 MB 11.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  375.9/376.0 MB 11.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  375.9/376.0 MB 11.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  375.9/376.0 MB 11.6 MB/s eta 0:00:01\n",
      "   --------------------------------------- 376.0/376.0 MB 11.4 MB/s eta 0:00:00\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.71.0-cp312-cp312-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   ------------------- -------------------- 2.1/4.3 MB 11.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  4.2/4.3 MB 11.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.3/4.3 MB 10.3 MB/s eta 0:00:00\n",
      "Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "   ---------------------------------------- 0.0/26.4 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 2.1/26.4 MB 10.7 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 4.2/26.4 MB 10.1 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 7.1/26.4 MB 11.5 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 10.0/26.4 MB 11.7 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 12.6/26.4 MB 12.1 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 14.9/26.4 MB 11.9 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 17.6/26.4 MB 12.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 20.2/26.4 MB 12.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 23.1/26.4 MB 12.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 25.7/26.4 MB 12.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.4/26.4 MB 12.2 MB/s eta 0:00:00\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   ----------------- ---------------------- 2.4/5.5 MB 12.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 5.0/5.5 MB 12.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 10.8 MB/s eta 0:00:00\n",
      "Downloading termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Installing collected packages: libclang, flatbuffers, termcolor, tensorboard-data-server, opt-einsum, grpcio, google-pasta, gast, astunparse, tensorboard, tensorflow\n",
      "Successfully installed astunparse-1.6.3 flatbuffers-25.2.10 gast-0.6.0 google-pasta-0.2.0 grpcio-1.71.0 libclang-18.1.1 opt-einsum-3.4.0 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorflow-2.19.0 termcolor-3.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "*pip install tensorflow*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c312043a-f356-410f-9d54-1ca1e9bf9373",
   "metadata": {},
   "outputs": [],
   "source": [
    "*from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d6bb9835-33b6-4eb0-844a-068385cea641",
   "metadata": {},
   "outputs": [],
   "source": [
    "*model = Sequential()8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3b5c5220-de43-4a9b-a319-5b37bc3d69b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,833</span> (34.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,833\u001b[0m (34.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,833</span> (34.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,833\u001b[0m (34.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "*model.add(Dense(128,input_shape=(3,),activation='relu',name='input'))\n",
    "model.add(Dense(64,activation='relu',name='layer_1'))\n",
    "model.add(Dense(1,activation='linear',name='output'))\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "model.summary()*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6ccfbd08-1ce7-440a-b782-141b2e588669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 545.4172 - mae: 21.7400 - val_loss: 696.4217 - val_mae: 23.6661\n",
      "Epoch 2/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 498.9538 - mae: 20.5696 - val_loss: 649.1369 - val_mae: 22.6249\n",
      "Epoch 3/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 420.0568 - mae: 19.0242 - val_loss: 583.7391 - val_mae: 21.1114\n",
      "Epoch 4/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 372.3493 - mae: 17.6394 - val_loss: 497.2712 - val_mae: 19.0314\n",
      "Epoch 5/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 282.2977 - mae: 15.3975 - val_loss: 395.1672 - val_mae: 16.5709\n",
      "Epoch 6/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 199.5345 - mae: 12.7733 - val_loss: 290.4421 - val_mae: 13.5197\n",
      "Epoch 7/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 110.3811 - mae: 9.2877 - val_loss: 205.5795 - val_mae: 10.8357\n",
      "Epoch 8/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 66.9668 - mae: 6.8156 - val_loss: 154.4747 - val_mae: 9.0749\n",
      "Epoch 9/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 46.7639 - mae: 5.5000 - val_loss: 127.8551 - val_mae: 7.8538\n",
      "Epoch 10/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 43.3421 - mae: 4.9701 - val_loss: 114.5064 - val_mae: 7.4592\n",
      "Epoch 11/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 35.6258 - mae: 4.3966 - val_loss: 104.9251 - val_mae: 7.1846\n",
      "Epoch 12/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 26.4978 - mae: 3.7553 - val_loss: 98.8924 - val_mae: 6.9847\n",
      "Epoch 13/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 27.8018 - mae: 4.0095 - val_loss: 94.7204 - val_mae: 6.8357\n",
      "Epoch 14/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 21.7812 - mae: 3.4815 - val_loss: 91.1064 - val_mae: 6.7315\n",
      "Epoch 15/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 27.4576 - mae: 3.7600 - val_loss: 89.9011 - val_mae: 6.6745\n",
      "Epoch 16/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 26.9454 - mae: 3.7724 - val_loss: 89.1236 - val_mae: 6.6224\n",
      "Epoch 17/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 21.1681 - mae: 3.4269 - val_loss: 87.5369 - val_mae: 6.5395\n",
      "Epoch 18/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 21.1101 - mae: 3.3355 - val_loss: 87.5154 - val_mae: 6.4990\n",
      "Epoch 19/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 23.8602 - mae: 3.6861 - val_loss: 85.6048 - val_mae: 6.4053\n",
      "Epoch 20/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 21.8814 - mae: 3.4166 - val_loss: 85.5051 - val_mae: 6.3701\n",
      "Epoch 21/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 21.9557 - mae: 3.4276 - val_loss: 85.8103 - val_mae: 6.3403\n",
      "Epoch 22/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 19.7906 - mae: 3.3233 - val_loss: 85.0894 - val_mae: 6.2396\n",
      "Epoch 23/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 15.9737 - mae: 2.9635 - val_loss: 83.0658 - val_mae: 6.1279\n",
      "Epoch 24/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 20.0638 - mae: 3.1916 - val_loss: 83.9923 - val_mae: 6.1430\n",
      "Epoch 25/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 17.6978 - mae: 3.0988 - val_loss: 82.6282 - val_mae: 6.0986\n",
      "Epoch 26/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 16.0052 - mae: 2.9333 - val_loss: 85.2929 - val_mae: 6.1491\n",
      "Epoch 27/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 16.8571 - mae: 2.9944 - val_loss: 83.8478 - val_mae: 6.0635\n",
      "Epoch 28/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 18.1883 - mae: 3.0310 - val_loss: 83.1596 - val_mae: 6.0086\n",
      "Epoch 29/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 15.6046 - mae: 2.8869 - val_loss: 82.9157 - val_mae: 5.9898\n",
      "Epoch 30/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 16.7462 - mae: 2.9065 - val_loss: 80.6508 - val_mae: 5.8786\n",
      "Epoch 31/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 14.3249 - mae: 2.8080 - val_loss: 81.8558 - val_mae: 5.8914\n",
      "Epoch 32/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 15.9518 - mae: 2.8906 - val_loss: 82.2425 - val_mae: 5.8828\n",
      "Epoch 33/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 16.0075 - mae: 2.9347 - val_loss: 81.6854 - val_mae: 5.8371\n",
      "Epoch 34/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 15.5137 - mae: 2.8509 - val_loss: 82.1564 - val_mae: 5.8114\n",
      "Epoch 35/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 16.9510 - mae: 2.9139 - val_loss: 82.5453 - val_mae: 5.8183\n",
      "Epoch 36/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 14.6019 - mae: 2.8508 - val_loss: 80.3143 - val_mae: 5.6951\n",
      "Epoch 37/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 15.6260 - mae: 2.8986 - val_loss: 81.2888 - val_mae: 5.6977\n",
      "Epoch 38/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 15.1582 - mae: 2.8889 - val_loss: 81.1119 - val_mae: 5.6788\n",
      "Epoch 39/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 14.8078 - mae: 2.8778 - val_loss: 80.6847 - val_mae: 5.6413\n",
      "Epoch 40/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 12.6566 - mae: 2.6256 - val_loss: 80.5904 - val_mae: 5.6236\n",
      "Epoch 41/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 16.4431 - mae: 2.8745 - val_loss: 80.1461 - val_mae: 5.6148\n",
      "Epoch 42/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 16.3262 - mae: 2.9122 - val_loss: 81.5899 - val_mae: 5.6493\n",
      "Epoch 43/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 12.7573 - mae: 2.6505 - val_loss: 79.8940 - val_mae: 5.5902\n",
      "Epoch 44/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 12.0701 - mae: 2.5591 - val_loss: 80.1573 - val_mae: 5.5790\n",
      "Epoch 45/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 17.4091 - mae: 2.8150 - val_loss: 79.0735 - val_mae: 5.5679\n",
      "Epoch 46/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 12.5250 - mae: 2.6324 - val_loss: 80.9896 - val_mae: 5.5966\n",
      "Epoch 47/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 13.3988 - mae: 2.6614 - val_loss: 81.5590 - val_mae: 5.5926\n",
      "Epoch 48/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 12.8340 - mae: 2.6346 - val_loss: 81.4899 - val_mae: 5.5732\n",
      "Epoch 49/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 11.8151 - mae: 2.5150 - val_loss: 80.6888 - val_mae: 5.5593\n",
      "Epoch 50/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 13.7491 - mae: 2.6618 - val_loss: 79.4865 - val_mae: 5.5185\n",
      "Epoch 51/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 11.9534 - mae: 2.4857 - val_loss: 80.5177 - val_mae: 5.5206\n",
      "Epoch 52/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 11.9009 - mae: 2.4920 - val_loss: 80.2944 - val_mae: 5.5004\n",
      "Epoch 53/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 13.2966 - mae: 2.6471 - val_loss: 80.3486 - val_mae: 5.4946\n",
      "Epoch 54/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 11.8711 - mae: 2.5278 - val_loss: 79.3506 - val_mae: 5.4779\n",
      "Epoch 55/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 11.5242 - mae: 2.4900 - val_loss: 81.3931 - val_mae: 5.4944\n",
      "Epoch 56/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 11.8778 - mae: 2.5210 - val_loss: 79.0640 - val_mae: 5.4859\n",
      "Epoch 57/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 11.7531 - mae: 2.5437 - val_loss: 81.1841 - val_mae: 5.5312\n",
      "Epoch 58/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 13.4218 - mae: 2.6043 - val_loss: 80.1143 - val_mae: 5.4691\n",
      "Epoch 59/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 13.9144 - mae: 2.6264 - val_loss: 79.7988 - val_mae: 5.4370\n",
      "Epoch 60/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 15.6790 - mae: 2.7774 - val_loss: 80.3819 - val_mae: 5.4278\n",
      "Epoch 61/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 12.0569 - mae: 2.5438 - val_loss: 79.9620 - val_mae: 5.4025\n",
      "Epoch 62/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 11.0305 - mae: 2.4265 - val_loss: 81.9569 - val_mae: 5.4338\n",
      "Epoch 63/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 12.3024 - mae: 2.5490 - val_loss: 79.8543 - val_mae: 5.3606\n",
      "Epoch 64/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 13.6613 - mae: 2.6487 - val_loss: 80.4878 - val_mae: 5.3626\n",
      "Epoch 65/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.6076 - mae: 2.3207 - val_loss: 78.7269 - val_mae: 5.2809\n",
      "Epoch 66/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 12.7018 - mae: 2.5913 - val_loss: 80.1365 - val_mae: 5.3158\n",
      "Epoch 67/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 11.8699 - mae: 2.5663 - val_loss: 81.5595 - val_mae: 5.3419\n",
      "Epoch 68/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 12.0284 - mae: 2.4616 - val_loss: 78.4326 - val_mae: 5.2521\n",
      "Epoch 69/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 13.0120 - mae: 2.4595 - val_loss: 79.3640 - val_mae: 5.2317\n",
      "Epoch 70/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 11.3445 - mae: 2.3876 - val_loss: 81.5742 - val_mae: 5.2784\n",
      "Epoch 71/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 11.6332 - mae: 2.5879 - val_loss: 78.5039 - val_mae: 5.1684\n",
      "Epoch 72/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.0433 - mae: 2.3608 - val_loss: 79.2143 - val_mae: 5.1700\n",
      "Epoch 73/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 12.2246 - mae: 2.4896 - val_loss: 79.6456 - val_mae: 5.1665\n",
      "Epoch 74/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 12.9794 - mae: 2.4598 - val_loss: 79.3113 - val_mae: 5.1530\n",
      "Epoch 75/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.1679 - mae: 2.3068 - val_loss: 77.8926 - val_mae: 5.0842\n",
      "Epoch 76/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.7246 - mae: 2.4630 - val_loss: 79.6718 - val_mae: 5.1051\n",
      "Epoch 77/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 11.8974 - mae: 2.5119 - val_loss: 78.5716 - val_mae: 5.1098\n",
      "Epoch 78/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 11.4954 - mae: 2.4431 - val_loss: 80.0087 - val_mae: 5.1462\n",
      "Epoch 79/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 11.8611 - mae: 2.4027 - val_loss: 79.7937 - val_mae: 5.0876\n",
      "Epoch 80/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 11.6992 - mae: 2.3625 - val_loss: 78.5181 - val_mae: 5.0623\n",
      "Epoch 81/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 10.3668 - mae: 2.4201 - val_loss: 79.4414 - val_mae: 5.1022\n",
      "Epoch 82/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 11.2744 - mae: 2.5106 - val_loss: 80.7552 - val_mae: 5.1072\n",
      "Epoch 83/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 12.7658 - mae: 2.4728 - val_loss: 79.8952 - val_mae: 5.0873\n",
      "Epoch 84/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 10.3901 - mae: 2.3383 - val_loss: 79.2185 - val_mae: 5.0498\n",
      "Epoch 85/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.3396 - mae: 2.3070 - val_loss: 79.0509 - val_mae: 5.0419\n",
      "Epoch 86/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.6717 - mae: 2.3055 - val_loss: 80.2281 - val_mae: 5.0905\n",
      "Epoch 87/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.7216 - mae: 2.3138 - val_loss: 78.4975 - val_mae: 5.0433\n",
      "Epoch 88/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 12.8256 - mae: 2.4799 - val_loss: 80.3972 - val_mae: 5.1064\n",
      "Epoch 89/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 12.2218 - mae: 2.4552 - val_loss: 80.0302 - val_mae: 5.0646\n",
      "Epoch 90/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 11.8596 - mae: 2.5192 - val_loss: 80.5962 - val_mae: 5.0882\n",
      "Epoch 91/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 13.9700 - mae: 2.6225 - val_loss: 82.0203 - val_mae: 5.1475\n",
      "Epoch 92/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 10.8585 - mae: 2.4156 - val_loss: 79.2909 - val_mae: 5.0260\n",
      "Epoch 93/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 11.2891 - mae: 2.4471 - val_loss: 79.9499 - val_mae: 5.0064\n",
      "Epoch 94/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 10.5768 - mae: 2.3469 - val_loss: 80.6348 - val_mae: 5.0535\n",
      "Epoch 95/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 11.7860 - mae: 2.4295 - val_loss: 79.8280 - val_mae: 5.0479\n",
      "Epoch 96/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.3639 - mae: 2.2871 - val_loss: 80.5891 - val_mae: 5.0271\n",
      "Epoch 97/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 11.8687 - mae: 2.4079 - val_loss: 79.8253 - val_mae: 5.0363\n",
      "Epoch 98/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.4767 - mae: 2.3222 - val_loss: 83.2281 - val_mae: 5.1482\n",
      "Epoch 99/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.7500 - mae: 2.3253 - val_loss: 81.1469 - val_mae: 5.0402\n",
      "Epoch 100/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.1761 - mae: 2.3221 - val_loss: 82.7287 - val_mae: 5.1006\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2a0e1f39be0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "*model.fit(x_train,y_train,epochs=100,validation_split=0.05)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "816a4953-7a73-402e-b16d-8e145a0fdcff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 21.3422 - mae: 3.1307\n"
     ]
    }
   ],
   "source": [
    "*output = model.evaluate(x_test,y_test)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b1435cdd-8052-4a44-bb04-9b3ba2ba1a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 23.18311882019043\n",
      "Mean Absolute Error: 3.1406633853912354\n"
     ]
    }
   ],
   "source": [
    "*print(f\"Mean Squared Error: {output[0]}\"\n",
    "      ,f\"Mean Absolute Error: {output[1]}\",sep=\"\\n\")*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dd671653-39c7-4dab-b31c-a1936bd2bfa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n"
     ]
    }
   ],
   "source": [
    "*y_pred = model.predict(x=x_test)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "66bdd9b0-296b-41f5-ae82-d7e688320a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([25.093832], dtype=float32), 28.4) (array([30.299273], dtype=float32), 31.1) (array([25.172424], dtype=float32), 23.5) (array([27.28462], dtype=float32), 26.6) (array([18.7459], dtype=float32), 19.6) (array([16.129267], dtype=float32), 14.3) (array([41.78438], dtype=float32), 50.0) (array([13.94441], dtype=float32), 14.3) (array([19.834103], dtype=float32), 20.7) (array([43.323418], dtype=float32), 37.6) (array([17.3466], dtype=float32), 20.4) (array([27.07491], dtype=float32), 27.5) (array([22.328934], dtype=float32), 36.2) (array([32.090633], dtype=float32), 32.0) (array([30.897818], dtype=float32), 33.1) (array([53.274887], dtype=float32), 48.8) (array([25.795008], dtype=float32), 24.6) (array([18.894735], dtype=float32), 26.4) (array([20.748083], dtype=float32), 23.2) (array([20.03347], dtype=float32), 17.0) (array([32.79455], dtype=float32), 41.3) (array([15.061151], dtype=float32), 14.9) (array([22.353466], dtype=float32), 18.5) (array([25.018143], dtype=float32), 25.0) (array([36.570057], dtype=float32), 36.4) (array([21.170464], dtype=float32), 19.5) (array([19.390654], dtype=float32), 27.1) (array([16.168386], dtype=float32), 14.9) (array([43.000553], dtype=float32), 46.0) (array([9.929784], dtype=float32), 17.9) (array([34.8436], dtype=float32), 30.3) (array([32.537716], dtype=float32), 31.6) (array([26.274803], dtype=float32), 23.1) (array([23.796246], dtype=float32), 24.7) (array([14.41772], dtype=float32), 16.7) (array([19.573078], dtype=float32), 18.3) (array([7.8996487], dtype=float32), 8.4) (array([32.049408], dtype=float32), 37.3) (array([24.382599], dtype=float32), 22.1) (array([24.371874], dtype=float32), 22.0) (array([39.385456], dtype=float32), 46.7) (array([26.239975], dtype=float32), 30.1) (array([13.423114], dtype=float32), 12.1) (array([28.57319], dtype=float32), 29.1) (array([17.82368], dtype=float32), 16.6) (array([27.28602], dtype=float32), 23.9) (array([17.613377], dtype=float32), 19.9) (array([18.402376], dtype=float32), 21.4) (array([44.984455], dtype=float32), 45.4) (array([15.900095], dtype=float32), 15.6) (array([19.895348], dtype=float32), 22.7) (array([13.954515], dtype=float32), 12.5) (array([20.201988], dtype=float32), 24.3) (array([39.409527], dtype=float32), 43.8) (array([23.431421], dtype=float32), 22.0) (array([35.121243], dtype=float32), 33.8) (array([19.114069], dtype=float32), 19.3) (array([18.925667], dtype=float32), 22.6) (array([20.499146], dtype=float32), 16.1) (array([20.887726], dtype=float32), 15.0) (array([17.977837], dtype=float32), 19.6) (array([21.10636], dtype=float32), 21.2) (array([52.405403], dtype=float32), 50.0) (array([57.720234], dtype=float32), 50.0) (array([27.133514], dtype=float32), 29.4) (array([14.310773], dtype=float32), 17.8) (array([24.50164], dtype=float32), 22.8) (array([11.865052], dtype=float32), 8.8) (array([27.105125], dtype=float32), 32.5) (array([39.517403], dtype=float32), 42.8) (array([16.065058], dtype=float32), 12.6) (array([27.897299], dtype=float32), 28.6) (array([17.32118], dtype=float32), 19.1) (array([21.657814], dtype=float32), 50.0) (array([20.781635], dtype=float32), 27.5) (array([11.834323], dtype=float32), 23.7) (array([48.271473], dtype=float32), 50.0) (array([9.293611], dtype=float32), 7.2) (array([19.812418], dtype=float32), 18.7) (array([32.259003], dtype=float32), 37.0) (array([19.846798], dtype=float32), 22.9) (array([25.316265], dtype=float32), 22.9) (array([19.164158], dtype=float32), 17.1) (array([24.571266], dtype=float32), 22.0) (array([31.455923], dtype=float32), 23.6) (array([24.8588], dtype=float32), 23.9) (array([25.632069], dtype=float32), 27.1) (array([33.849472], dtype=float32), 29.0) (array([24.297695], dtype=float32), 22.2) (array([9.499264], dtype=float32), 7.0) (array([23.4102], dtype=float32), 20.7) (array([20.811863], dtype=float32), 18.5) (array([23.926182], dtype=float32), 21.6) (array([24.597275], dtype=float32), 23.0) (array([18.658743], dtype=float32), 16.0) (array([20.349136], dtype=float32), 15.0) (array([25.697395], dtype=float32), 23.9) (array([19.684338], dtype=float32), 24.4) (array([20.472355], dtype=float32), 22.6) (array([17.992435], dtype=float32), 19.8) (array([21.825974], dtype=float32), 22.2) (array([19.244308], dtype=float32), 18.6) (array([19.342865], dtype=float32), 19.7) (array([22.865122], dtype=float32), 23.1) (array([12.9991455], dtype=float32), 13.5) (array([21.274544], dtype=float32), 21.2) (array([18.309582], dtype=float32), 23.1) (array([15.172555], dtype=float32), 13.6) (array([28.460712], dtype=float32), 22.8) (array([23.173513], dtype=float32), 18.2) (array([11.598226], dtype=float32), 13.1) (array([17.381823], dtype=float32), 23.2) (array([25.296864], dtype=float32), 22.8) (array([25.0396], dtype=float32), 25.1) (array([21.70008], dtype=float32), 18.9) (array([13.0695], dtype=float32), 10.9) (array([14.045796], dtype=float32), 19.3) (array([19.98859], dtype=float32), 17.4) (array([18.243507], dtype=float32), 15.6) (array([20.11837], dtype=float32), 20.6) (array([29.468552], dtype=float32), 50.0) (array([35.429844], dtype=float32), 32.7) (array([20.76011], dtype=float32), 21.8) (array([16.051008], dtype=float32), 13.4) (array([17.137169], dtype=float32), 16.6) (array([23.391113], dtype=float32), 23.6) (array([12.603938], dtype=float32), 11.0)\n"
     ]
    }
   ],
   "source": [
    "*print(*zip(y_pred,y_test))*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26dc57b2-eb84-4dd7-8d47-177a28ccede8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
